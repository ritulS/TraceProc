{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO\n",
    "# 1) Randomize '(?)' nodes\n",
    "# 2) Saving final traces to pkl/json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace builiding code\n",
    "class Trace:\n",
    "    def __init__(self):\n",
    "        self.calls = []\n",
    "\n",
    "class Node_info:\n",
    "    def __init__(self, num_id, n_type):\n",
    "        self.num_id = num_id\n",
    "        self.n_type = n_type\n",
    "\n",
    "class Call:\n",
    "    def __init__(self, traceid, timestamp, rpcid, um, dm, rpctype, interface, rt):\n",
    "        self.traceid = traceid\n",
    "        self.timestamp = timestamp\n",
    "        self.rpcid = rpcid\n",
    "        self.um = um\n",
    "        self.dm = dm \n",
    "        self.rpctype = rpctype\n",
    "        self.interface = interface\n",
    "        self.rt = rt\n",
    "    def string(self):\n",
    "        return self.traceid + \",\" + str(self.timestamp) + \",\" + self.rpcid + \",\" + self.um + \",\" + self.dm + \",\" +\\\n",
    "            self.rpctype + \",\" + self.interface + \",\" + str(self.rt)\n",
    "\n",
    "def csv_to_df(file: str):\n",
    "    use_columns = list(range(9)) \n",
    "    df = pd.read_csv(file,delimiter=',', usecols=use_columns)\n",
    "    return df\n",
    "\n",
    "def extract_traceid_rows(df, tid):\n",
    "    '''\n",
    "    Returns a list of rpc calls in tid\n",
    "    '''\n",
    "    f_df = df[df['traceid'] == tid]\n",
    "    tid_calls = [\n",
    "        Call(\n",
    "            str(row.traceid), \n",
    "            int(row.timestamp), \n",
    "            str(row.rpcid), \n",
    "            str(row.um), \n",
    "            str(row.dm), \n",
    "            str(row.rpctype), \n",
    "            str(row.interface), \n",
    "            int(row.rt)\n",
    "        ) for row in f_df.itertuples(index=False)\n",
    "    ]\n",
    "    return tid_calls\n",
    "\n",
    "def get_call_depth(rpc_id):\n",
    "    if rpc_id == \"0\":\n",
    "        return 1\n",
    "    else:\n",
    "        call_depth = 0\n",
    "        for i in rpc_id:\n",
    "            if i == \".\":\n",
    "                call_depth += 1\n",
    "    return call_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of tids (traces):  10421\n",
      "Num of unique nodes:  3656\n"
     ]
    }
   ],
   "source": [
    "# types :  ['userDefined', 'db', 'http', 'mq', 'rpc', 'mc']\n",
    "# Extract to dataframe\n",
    "df = csv_to_df(\"./casper_rebuild.csv\")\n",
    "\n",
    "# Extract all tids\n",
    "tids_list = df['traceid'].unique().tolist()\n",
    "unique_nodes = list(set(df['um'].unique().tolist() + df['dm'].unique().tolist()))\n",
    "num_traces = len(tids_list)\n",
    "print(\"Num of tids (traces): \", num_traces)\n",
    "print(\"Num of unique nodes: \", len(unique_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers after Error Correction\n",
      "Num of tids (traces):  10421\n",
      "Num of unique nodes:  3655\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Unknown node error correction\n",
    "Replace '(?)' with a random node\n",
    "'''\n",
    "# Select random ~500 node ids\n",
    "rand_um_nids = list(df['um'].sample(1500, random_state=1))\n",
    "rand_dm_nids = list(df['dm'].sample(1500, random_state=1))\n",
    "rand_um_nids = [um for um in rand_um_nids if um != '(?)']\n",
    "rand_dm_nids = [dm for dm in rand_dm_nids if dm != '(?)']\n",
    "replacement_nodes = list(set(rand_um_nids + rand_dm_nids))\n",
    "\n",
    "# Randomly assign nodeids to unknown nodes\n",
    "for i in range(len(df)):\n",
    "    if df.at[i, 'um'] == '(?)':\n",
    "        df.at[i, 'um'] = random.choice(replacement_nodes)\n",
    "    if df.at[i, 'dm'] == '(?)':\n",
    "        df.at[i, 'dm'] = random.choice(replacement_nodes)\n",
    "\n",
    "tids_list = df['traceid'].unique()\n",
    "unique_nodes = list(set(df['um'].unique().tolist() + df['dm'].unique().tolist()))\n",
    "num_traces = len(tids_list)\n",
    "print('Numbers after Error Correction')\n",
    "print(\"Num of tids (traces): \", num_traces)\n",
    "print(\"Num of unique nodes: \", len(unique_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350980 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350980/350980 [00:04<00:00, 74950.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NIS calc\n",
    "Node Metrics: [type, NIS]\n",
    "'''\n",
    "nis_dict = {}\n",
    "ctr = 0\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    ctr += 1\n",
    "    um_node = row.um\n",
    "    dm_node = row.dm\n",
    "    # Update nis dict for um_node\n",
    "    if um_node in nis_dict:\n",
    "        if row.traceid not in nis_dict[um_node]:\n",
    "            nis_dict[um_node].append(row.traceid)\n",
    "    else:\n",
    "        nis_dict[um_node] = [row.traceid]\n",
    "    # Update nis dict for dm_node\n",
    "    if dm_node in nis_dict:\n",
    "        if row.traceid not in nis_dict[dm_node]:\n",
    "            nis_dict[dm_node].append(row.traceid)\n",
    "    else:\n",
    "        nis_dict[dm_node] = [row.traceid]\n",
    "    # if ctr == 1000:\n",
    "    #     break\n",
    "print(len(nis_dict))\n",
    "# replace traceid list with NIS\n",
    "num_traces = 10421 ### TO BE REPLACED\n",
    "for node in nis_dict:\n",
    "    nis_dict[node] = set(nis_dict[node])\n",
    "    nis = len(nis_dict[node])/num_traces ### TO BE REPLACED\n",
    "    nis_dict[node] = [round(nis,7)]\n",
    "# print(nis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nis_dict)\n",
    "print(len(nis_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10421/10421 [02:41<00:00, 64.37it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Trace metrics calc\n",
    "Trace Metrics: [trace_depth, TIS, initial_node, num_sf, num_sl]\n",
    "'''\n",
    "\n",
    "trace_met_dict = {}\n",
    "cd_strat_dict = {} # dict. key: cd, val: [tid ,tis]\n",
    "# check_unique_nodes = []\n",
    "for i in tqdm(range(len(tids_list))):\n",
    "    ctr = 0\n",
    "    # if i in [0,1,2]:\n",
    "    #     continue\n",
    "    tid_calls = extract_traceid_rows(df, tids_list[i])\n",
    "    initial_node = \"\"\n",
    "    t_edges = [] # list of edges of trace\n",
    "    t_sf_ctr = 0\n",
    "    t_sl_ctr = 0\n",
    "    trace_depth = 0\n",
    "    for call in tid_calls:\n",
    "        t_edges.append([call.um, call.dm])\n",
    "        # if call.um not in check_unique_nodes:\n",
    "        #     check_unique_nodes.append(call.um)\n",
    "        # if call.dm not in check_unique_nodes:\n",
    "        #     check_unique_nodes.append(call.dm)\n",
    "        call_depth = get_call_depth(call.rpcid)\n",
    "        if call_depth > trace_depth: # update trace depth\n",
    "            trace_depth = call_depth\n",
    "        if call.rpcid == \"0\": # get initial node of trace\n",
    "            initial_node = call.dm\n",
    "            # print(initial_node)\n",
    "        if call.rpctype == \"db\": # get sf sl node count\n",
    "            t_sf_ctr += 1\n",
    "        else: \n",
    "            t_sl_ctr += 1\n",
    "\n",
    "    # TIS calculation\n",
    "    t_nodes = []\n",
    "    for edge in t_edges:\n",
    "        for node in edge:\n",
    "            if node not in t_nodes:\n",
    "                t_nodes.append(node)\n",
    "    tis = 0\n",
    "    for node in t_nodes:\n",
    "        nis_temp = nis_dict[node][0]\n",
    "        tis += nis_temp \n",
    "    tis = tis/len(t_nodes)\n",
    "\n",
    "    # Collecting data for stratification\n",
    "    if trace_depth not in cd_strat_dict:\n",
    "        cd_strat_dict[trace_depth] = []\n",
    "    cd_strat_dict[trace_depth].append([tids_list[i],tis])\n",
    "\n",
    "    trace_met_dict[tids_list[i]] = [trace_depth, tis, initial_node, t_sf_ctr, t_sl_ctr]\n",
    "\n",
    "    # if ctr == 5:\n",
    "    #     break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3655\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# G_check = nx.DiGraph()\n",
    "# G_check.add_edges_from(check)\n",
    "# print(len(G_check.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Stratification\n",
    "'''\n",
    "\n",
    "cd_percent_arr = [] # [valid call depth, % of tids of resp cd]\n",
    "# ctr is used as the total num of tids\n",
    "\n",
    "# Collecting cd percentage in the original trace\n",
    "for cd in cd_strat_dict:\n",
    "    percent_t_cd = 100 * (len(cd_strat_dict[cd])/num_traces)\n",
    "    cd_percent_arr.append([cd, percent_t_cd])\n",
    "    cd_strat_dict[cd] = sorted(cd_strat_dict[cd], key=lambda x: x[1], reverse=True) # sorting tids based on tis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 18.606659629594088], [8, 6.47730544093657], [4, 30.505709624796083], [3, 16.38038575952404], [10, 2.303041934555225], [6, 8.895499472219557], [9, 3.185874676134728], [11, 2.293445926494578], [13, 1.4873812494002496], [14, 0.3646483063045773], [12, 2.638902216677862], [2, 1.7272814509164187], [7, 3.5313309663180115], [0, 0.31666826600134346], [1, 0.8156606851549755], [15, 0.1919201612129354], [16, 0.11515209672776125], [20, 0.028788024181940312], [17, 0.07676806448517416], [19, 0.01919201612129354], [18, 0.028788024181940312], [21, 0.00959600806064677]]\n",
      "99.99999999999999\n"
     ]
    }
   ],
   "source": [
    "print(cd_percent_arr)\n",
    "res= 0\n",
    "for i in cd_percent_arr:\n",
    "    res += i[1]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NIS: Priority Sampling\n",
    "'''\n",
    "n = 500 # Reduced num of nodes (USER DEFINED)\n",
    "# Sorted nis_dict based on NIS values\n",
    "nid_nis_arr = [[nid, nis] for nid, nis in nis_dict.items()]\n",
    "sorted_node_items = sorted(nid_nis_arr, key=lambda item: item[1], reverse=True)\n",
    "sampled_nodes = []\n",
    "\n",
    "for node in sorted_node_items[:n]:\n",
    "    sampled_nodes.append(node[0])\n",
    "    \n",
    "print(len(sampled_nodes))\n",
    "# nid_nis_arr_sorted_dict = dict(sorted_node_items)\n",
    "# sampled_nodes = list(nid_nis_arr_sorted_dict.keys()[:n]) # List of selected node ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TIS: Priority Sampling\n",
    "'''\n",
    "t_red = 5000 # reduced num of traces (USER DEFINED)\n",
    "sampled_tids_inter = [] # T_inter\n",
    "\n",
    "\n",
    "# Priority sampling based on TIS\n",
    "cd_ctr = 0\n",
    "for cd in cd_percent_arr: \n",
    "    num_traces_to_sample_for_cd = int(t_red * cd[1]/100)\n",
    "    \n",
    "    if num_traces_to_sample_for_cd < 1:\n",
    "        cd_ctr += 1 \n",
    "        continue\n",
    "    cd_traces_list = cd_strat_dict[cd[0]]\n",
    "    cd_priority_sample = cd_traces_list[:num_traces_to_sample_for_cd]\n",
    "    sampled_cd_tids = [x[0] for x in cd_priority_sample]\n",
    "    sampled_tids_inter.extend(sampled_cd_tids)\n",
    "    # print(cd_priority_sample)\n",
    "print(cd_ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0b5113ef15919489099687000e6d6b', '0b133c0815919574119565000e5f21', '0b141bcf15919393961062000e1f1f']\n"
     ]
    }
   ],
   "source": [
    "print(sampled_tids_inter[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NODE PRUNING\n",
    "Remove all nodes from T_inter that is not in sampled_nodes\n",
    "'''\n",
    "\n",
    "def cycle_func(A, B, pred_flag):\n",
    "    # Cycle through B if it's shorter than A\n",
    "    B_cycle = cycle(B)\n",
    "    # Create tuples by pairing elements from A with elements from the cycled B\n",
    "    if pred_flag == 1: # pred flag is used to check if direction is from pred to succ\n",
    "        result = [(a, next(B_cycle)) for a in A]\n",
    "    else:\n",
    "        result = [(next(B_cycle), a) for a in A]\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_node_with_reconnect(G, node):\n",
    "    '''\n",
    "    Remove given node and check if graph breaks. If yes, connect pred nodes\n",
    "    to succ nodes and then remove given node.\n",
    "    returns: Updated graph after removing the given node\n",
    "    '''\n",
    "    num_comp_before_removal = len(list(nx.weakly_connected_components(G)))\n",
    "    G_temp = G.copy()\n",
    "    G_temp.remove_node(node)\n",
    "    num_comp_after_removal = len(list(nx.weakly_connected_components(G_temp)))\n",
    "\n",
    "    # If bridge node\n",
    "    if num_comp_after_removal > num_comp_before_removal:\n",
    "        pred_nodes = list(G.predecessors(node))\n",
    "        succ_nodes = list(G.successors(node))\n",
    "        if len(succ_nodes) == 0: # if leaf node\n",
    "            G.remove_node(node)\n",
    "            return G\n",
    "        if len(pred_nodes) >= len(succ_nodes):\n",
    "            edges_to_add = cycle_func(pred_nodes, succ_nodes, 1)\n",
    "        else:\n",
    "            edges_to_add = cycle_func(succ_nodes, pred_nodes, 0)\n",
    "        for edge in edges_to_add:\n",
    "            G.add_edge(edge[0], edge[1])\n",
    "    \n",
    "    # If not bridge \n",
    "    G.remove_node(node)\n",
    "\n",
    "    return G\n",
    "\n",
    "def prune_nodes_testy(sampled_tids_inter, sampled_nodes, df):\n",
    "    '''\n",
    "    Args: sampled_tids_inter= list of selected trace ids,\n",
    "          sampled_nodes= list of selected node ids\n",
    "    Returns: two Dicts(original & pruned); Key=tid, Val=list of edges to build tid\n",
    "    '''\n",
    "    T_prime = {}\n",
    "    T_original = {}\n",
    "    ctr = 0\n",
    "    check_unique_nodes = []\n",
    "    nodes_removed_per_trace = []\n",
    "\n",
    "    for tid in tqdm(sampled_tids_inter):\n",
    "        ctr += 1\n",
    "        nodes_to_remove = []# get list of nodes to remove in trace\n",
    "        tid_calls = extract_traceid_rows(df, tid)\n",
    "        t_edges = []\n",
    "        for call in tid_calls:\n",
    "            t_edges.append([call.um, call.dm])\n",
    "            if call.um not in check_unique_nodes:\n",
    "                check_unique_nodes.append(call.um)\n",
    "            if call.dm not in check_unique_nodes:\n",
    "                check_unique_nodes.append(call.dm)\n",
    "            \n",
    "        # Build pre-pruned graph\n",
    "        G = nx.DiGraph()\n",
    "        G.add_edges_from(t_edges)\n",
    "        T_original[tid] = t_edges\n",
    "\n",
    "        # Handling broken graphs (~40% are broken)\n",
    "        num_comp_before_removal = len(list(nx.weakly_connected_components(G)))\n",
    "        if num_comp_before_removal > 1:\n",
    "            # select the largest component\n",
    "            largest_comp = max(nx.weakly_connected_components(G), key=len)\n",
    "            G = G.subgraph(largest_comp).copy()\n",
    "        \n",
    "        for node in G.nodes():\n",
    "            if node not in sampled_nodes:\n",
    "                nodes_to_remove.append(node)\n",
    "        \n",
    "        # nodes_to_remove = list(set(nodes_to_remove))\n",
    "        nodes_removed_per_trace.append(len(nodes_to_remove))\n",
    "\n",
    "        # Do node pruning\n",
    "        for node in nodes_to_remove:\n",
    "            if node in G:\n",
    "                G = remove_node_with_reconnect(G, node)\n",
    "\n",
    "        # edges in pruned trace \n",
    "        all_edges = list(G.edges())\n",
    "        T_prime[tid] = all_edges\n",
    "\n",
    "    print('Unique nodes in selected tids: ', len(check_unique_nodes))\n",
    "    print('Total nodes removed(sum:max:min): ', sum(nodes_removed_per_trace), ':', max(nodes_removed_per_trace), ':', min(nodes_removed_per_trace))\n",
    "    # print('Number of broken traces: ', len(broken_traces))\n",
    "    return T_prime, T_original\n",
    "\n",
    "\n",
    "def save_sampled_graph_as_pkl(traces_dict, file_name):\n",
    "    with open(file_name+'.pkl', 'wb') as pkl_file:\n",
    "        pickle.dump(traces_dict, pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4988/4988 [01:17<00:00, 64.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique nodes in selected tids:  1024\n",
      "Total nodes removed(sum:max:min):  1162 : 25 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Pruning Check\n",
    "T_prime, T_original = prune_nodes_testy(sampled_tids_inter, sampled_nodes, df)\n",
    "# print(len(sampled_nodes))\n",
    "save_sampled_graph_as_pkl(T_prime, 'downsampled_graphs/500nodes_5000traces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "483\n"
     ]
    }
   ],
   "source": [
    "def buildg_from_tracesdict(traces_dict):\n",
    "\n",
    "    full_graph_edge_list = []\n",
    "    for edge_list in traces_dict.values():\n",
    "        full_graph_edge_list.extend(edge_list)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(full_graph_edge_list)\n",
    "\n",
    "    return G\n",
    "\n",
    "G_prime = buildg_from_tracesdict(T_prime)\n",
    "G_original = buildg_from_tracesdict(T_original)\n",
    "print(len(G_original.nodes()))\n",
    "print(len(G_prime.nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4988\n"
     ]
    }
   ],
   "source": [
    "print(len(T_prime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# pos = nx.spring_layout(G)  # positions for all nodes\n",
    "\n",
    "# # Draw nodes\n",
    "# nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue')\n",
    "\n",
    "# # Draw edges\n",
    "# nx.draw_networkx_edges(G, pos, edgelist=G.edges(), arrowstyle='->', arrowsize=20)\n",
    "\n",
    "# len(list(nx.weakly_connected_components(G)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
